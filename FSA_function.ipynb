{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### This is an implementation of Fuzzy Similiazrity Analysis (FSA) for improvement of Machine learning-based predictions of Wate Quality Parameters\n",
    "\n",
    "# function for distance calcualtion\n",
    "def calculate_distance(v1, v2):\n",
    "    return np.sqrt(np.sum((v1 - v2) ** 2)) \n",
    "\n",
    "# FSA function\n",
    "def FSA(x_training, x_prediction, alpha, beta, k):\n",
    "    \n",
    "    # Inputs: \n",
    "        #       x_training:Sentinel-2 (S2) feature collection of training data\n",
    "        #       x_prediction:Sentinel-2 (S2) feature collection of prediction samples\n",
    "        #       alpha, beta: in FSA formula\n",
    "        #       k: number_of_nearest\n",
    "        \n",
    "    # Outputs:\n",
    "        #       Weights: non-normalized weights of k similar samples\n",
    "        #       ensemble_weights: Normalized Weights of k similar samples\n",
    "        #       Weights_id: Training samples which are selected for FSA-based improvements\n",
    "        \n",
    "    \n",
    "    Phi = np.zeros((x_training.shape[0], x_prediction.shape[0]))\n",
    "    similarity_scores = np.zeros((x_training.shape[0], x_prediction.shape[0]))\n",
    "    Weights = np.zeros((k, x_prediction.shape[0]))\n",
    "    Weights_id = np.zeros((k, x_prediction.shape[0]))\n",
    "    \n",
    "    for i in range(x_prediction.shape[0]):\n",
    "        for j in range(x_training.shape[0]):\n",
    "            Phi[j, i] = calculate_distance(x_training[j, :], x_prediction[i,:])\n",
    "            similarity_scores[j,i] = np.exp( -(-np.log(alpha) / (beta ** 2)) * (Phi[j, i] ** 2) )\n",
    "        \n",
    "        Nearest_Samples = similarity_scores[:,i].argsort()[0: k]\n",
    "        Nearest_Distances = similarity_scores[Nearest_Samples,i]\n",
    "        \n",
    "        for k_th_similarsample in range(k):\n",
    "            Weights[k_th_similarsample, i] = (Nearest_Distances[k_th_similarsample]) * np.exp(-Nearest_Distances[k_th_similarsample]/beta)\n",
    "            Weights_id[k_th_similarsample,i] = Nearest_Samples[k_th_similarsample]\n",
    "            \n",
    "    ensemble_weights = Weights / np.sum(Weights, axis = 0)\n",
    "        \n",
    "    return Weights, Weights_id, ensemble_weights, similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDN4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
